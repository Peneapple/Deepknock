{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f5a4f5",
   "metadata": {},
   "source": [
    "split dataset into 20 parts, in which each of them will serve as training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install -c conda-forge imbalanced-learn\n",
    "# conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d45de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460f398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 GPU\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04690b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e4a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91edb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 PyTorch 模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def run_pytorch_MLP(X_train, X_test, y_train, y_test, \n",
    "                    batch_size, learning_rate, weight_decay, num_train_epochs):\n",
    "    # 使用 SMOTE\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 将 numpy 数据转换为 torch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = MLP()\n",
    "    model.to(device)  # 移动模型到 GPU\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test.to(device))\n",
    "            validation_loss = criterion(outputs, y_test.to(device))\n",
    "            validation_losses.append(validation_loss.item())\n",
    "        \n",
    "        print(f'Epoch {epoch+1} - Train Loss: {running_loss / len(train_loader):.3f}, Validation Loss: {validation_loss.item():.3f}')\n",
    "\n",
    "    return model, train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f6974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read\n",
      "Epoch 1 - Train Loss: 0.041, Validation Loss: 0.004\n",
      "Epoch 2 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 3 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 4 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 5 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 6 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 7 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 8 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 9 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 10 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 11 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 12 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 13 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 14 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 15 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 16 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 17 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 18 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 19 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 20 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "test read\n",
      "Prediction time: 0.11310482025146484 seconds\n",
      "Confusion Matrix:\n",
      "[[2491301      23]\n",
      " [   1212 2007464]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10610651969909668 seconds\n",
      "Confusion Matrix:\n",
      "[[2493380      30]\n",
      " [   1501 2005089]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10682845115661621 seconds\n",
      "Confusion Matrix:\n",
      "[[2494942      35]\n",
      " [   1424 2003599]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1481778621673584 seconds\n",
      "Confusion Matrix:\n",
      "[[2492828      31]\n",
      " [   1502 2005639]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1508176326751709 seconds\n",
      "Confusion Matrix:\n",
      "[[2494074      23]\n",
      " [   1460 2004443]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11565661430358887 seconds\n",
      "Confusion Matrix:\n",
      "[[2492349      35]\n",
      " [   1416 2006200]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11838459968566895 seconds\n",
      "Confusion Matrix:\n",
      "[[2491947      33]\n",
      " [   1503 2006517]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.15096163749694824 seconds\n",
      "Confusion Matrix:\n",
      "[[2493387      32]\n",
      " [   1501 2005080]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11727380752563477 seconds\n",
      "Confusion Matrix:\n",
      "[[2492121      32]\n",
      " [   1409 2006438]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11630964279174805 seconds\n",
      "Confusion Matrix:\n",
      "[[2493527      30]\n",
      " [   1455 2004988]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.12002897262573242 seconds\n",
      "Confusion Matrix:\n",
      "[[2492685      18]\n",
      " [   1468 2005829]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1270918846130371 seconds\n",
      "Confusion Matrix:\n",
      "[[2494586      30]\n",
      " [   1444 2003940]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11560392379760742 seconds\n",
      "Confusion Matrix:\n",
      "[[2492999      34]\n",
      " [   1446 2005521]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.12344193458557129 seconds\n",
      "Confusion Matrix:\n",
      "[[2495406      26]\n",
      " [   1409 2003159]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10446310043334961 seconds\n",
      "Confusion Matrix:\n",
      "[[2493654      26]\n",
      " [   1397 2004923]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11977767944335938 seconds\n",
      "Confusion Matrix:\n",
      "[[2493777      27]\n",
      " [   1465 2004731]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10870957374572754 seconds\n",
      "Confusion Matrix:\n",
      "[[2493877      25]\n",
      " [   1459 2004639]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1089627742767334 seconds\n",
      "Confusion Matrix:\n",
      "[[2493181      28]\n",
      " [   1512 2005279]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9992\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1126852035522461 seconds\n",
      "Confusion Matrix:\n",
      "[[2493444      14]\n",
      " [   1497 2005045]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09231805801391602 seconds\n",
      "Confusion Matrix:\n",
      "[[2250157      31]\n",
      " [   1294 1809196]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "data read\n",
      "Epoch 1 - Train Loss: 0.040, Validation Loss: 0.004\n",
      "Epoch 2 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 3 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 4 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 5 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 6 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 7 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 8 - Train Loss: 0.004, Validation Loss: 0.005\n",
      "Epoch 9 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 10 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 11 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 12 - Train Loss: 0.004, Validation Loss: 0.005\n",
      "Epoch 13 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 14 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 15 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 16 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 17 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 18 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 19 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 20 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "test read\n",
      "Prediction time: 0.08864307403564453 seconds\n",
      "Confusion Matrix:\n",
      "[[2490973     351]\n",
      " [   1242 2007434]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10201358795166016 seconds\n",
      "Confusion Matrix:\n",
      "[[2493107     303]\n",
      " [   1022 2005568]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08895134925842285 seconds\n",
      "Confusion Matrix:\n",
      "[[2494615     362]\n",
      " [   1225 2003798]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.0798804759979248 seconds\n",
      "Confusion Matrix:\n",
      "[[2492518     341]\n",
      " [   1291 2005850]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08937287330627441 seconds\n",
      "Confusion Matrix:\n",
      "[[2493721     376]\n",
      " [   1277 2004626]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09117746353149414 seconds\n",
      "Confusion Matrix:\n",
      "[[2492031     353]\n",
      " [   1217 2006399]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08903741836547852 seconds\n",
      "Confusion Matrix:\n",
      "[[2491643     337]\n",
      " [   1274 2006746]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08991670608520508 seconds\n",
      "Confusion Matrix:\n",
      "[[2493092     327]\n",
      " [   1279 2005302]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09088444709777832 seconds\n",
      "Confusion Matrix:\n",
      "[[2491820     333]\n",
      " [   1174 2006673]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09028506278991699 seconds\n",
      "Confusion Matrix:\n",
      "[[2493181     376]\n",
      " [   1192 2005251]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08994674682617188 seconds\n",
      "Confusion Matrix:\n",
      "[[2492359     344]\n",
      " [   1242 2006055]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08026981353759766 seconds\n",
      "Confusion Matrix:\n",
      "[[2494282     334]\n",
      " [   1254 2004130]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09151911735534668 seconds\n",
      "Confusion Matrix:\n",
      "[[2492680     353]\n",
      " [   1243 2005724]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09146595001220703 seconds\n",
      "Confusion Matrix:\n",
      "[[2495100     332]\n",
      " [   1225 2003343]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.0902099609375 seconds\n",
      "Confusion Matrix:\n",
      "[[2493349     331]\n",
      " [   1162 2005158]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.0894780158996582 seconds\n",
      "Confusion Matrix:\n",
      "[[2493465     339]\n",
      " [   1262 2004934]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08940005302429199 seconds\n",
      "Confusion Matrix:\n",
      "[[2493539     363]\n",
      " [   1227 2004871]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09197473526000977 seconds\n",
      "Confusion Matrix:\n",
      "[[2492857     352]\n",
      " [   1261 2005530]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08774375915527344 seconds\n",
      "Confusion Matrix:\n",
      "[[2493118     340]\n",
      " [   1249 2005293]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08124303817749023 seconds\n",
      "Confusion Matrix:\n",
      "[[2249869     319]\n",
      " [   1073 1809417]]\n",
      "Precision: 0.9998\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "data read\n",
      "Epoch 1 - Train Loss: 0.041, Validation Loss: 0.004\n",
      "Epoch 2 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 3 - Train Loss: 0.004, Validation Loss: 0.005\n",
      "Epoch 4 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 5 - Train Loss: 0.004, Validation Loss: 0.005\n",
      "Epoch 6 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 7 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 8 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 9 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 10 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 11 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 12 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 13 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 14 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 15 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 16 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 17 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 18 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 19 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 20 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "test read\n",
      "Prediction time: 0.1430208683013916 seconds\n",
      "Confusion Matrix:\n",
      "[[2491220     104]\n",
      " [   1268 2007408]]\n",
      "Precision: 0.9999\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.167191743850708 seconds\n",
      "Confusion Matrix:\n",
      "[[2493338      72]\n",
      " [   1340 2005250]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.10426902770996094 seconds\n",
      "Confusion Matrix:\n",
      "[[2494893      84]\n",
      " [   1089 2003934]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08973884582519531 seconds\n",
      "Confusion Matrix:\n",
      "[[2492766      93]\n",
      " [   1329 2005812]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08926987648010254 seconds\n",
      "Confusion Matrix:\n",
      "[[2494019      78]\n",
      " [   1309 2004594]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09093189239501953 seconds\n",
      "Confusion Matrix:\n",
      "[[2492282     102]\n",
      " [   1272 2006344]]\n",
      "Precision: 0.9999\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.0900125503540039 seconds\n",
      "Confusion Matrix:\n",
      "[[2491871     109]\n",
      " [   1364 2006656]]\n",
      "Precision: 0.9999\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09000778198242188 seconds\n",
      "Confusion Matrix:\n",
      "[[2493304     115]\n",
      " [   1306 2005275]]\n",
      "Precision: 0.9999\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08691620826721191 seconds\n",
      "Confusion Matrix:\n",
      "[[2492055      98]\n",
      " [   1231 2006616]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09183955192565918 seconds\n",
      "Confusion Matrix:\n",
      "[[2493466      91]\n",
      " [   1258 2005185]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09568953514099121 seconds\n",
      "Confusion Matrix:\n",
      "[[2492614      89]\n",
      " [   1338 2005959]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07974910736083984 seconds\n",
      "Confusion Matrix:\n",
      "[[2494520      96]\n",
      " [   1288 2004096]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09263944625854492 seconds\n",
      "Confusion Matrix:\n",
      "[[2492935      98]\n",
      " [   1286 2005681]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08005785942077637 seconds\n",
      "Confusion Matrix:\n",
      "[[2495344      88]\n",
      " [   1285 2003283]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07959342002868652 seconds\n",
      "Confusion Matrix:\n",
      "[[2493594      86]\n",
      " [   1236 2005084]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07990694046020508 seconds\n",
      "Confusion Matrix:\n",
      "[[2493705      99]\n",
      " [   1355 2004841]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07951617240905762 seconds\n",
      "Confusion Matrix:\n",
      "[[2493814      88]\n",
      " [   1296 2004802]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.08016133308410645 seconds\n",
      "Confusion Matrix:\n",
      "[[2493133      76]\n",
      " [   1347 2005444]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9996\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07957983016967773 seconds\n",
      "Confusion Matrix:\n",
      "[[2493375      83]\n",
      " [   1321 2005221]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9993\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.07831907272338867 seconds\n",
      "Confusion Matrix:\n",
      "[[2250099      89]\n",
      " [   1097 1809393]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "data read\n",
      "Epoch 5 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 6 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 7 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 8 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 9 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 10 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 11 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 12 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 13 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 14 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 15 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 16 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 17 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 18 - Train Loss: 0.004, Validation Loss: 0.004\n",
      "Epoch 19 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "Epoch 20 - Train Loss: 0.004, Validation Loss: 0.003\n",
      "test read\n",
      "Prediction time: 0.13950490951538086 seconds\n",
      "Confusion Matrix:\n",
      "[[2491309      15]\n",
      " [    989 2007687]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9998\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.11931920051574707 seconds\n",
      "Confusion Matrix:\n",
      "[[2493394      16]\n",
      " [   1041 2005549]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.15022659301757812 seconds\n",
      "Confusion Matrix:\n",
      "[[2494963      14]\n",
      " [   1022 2004001]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.14966058731079102 seconds\n",
      "Confusion Matrix:\n",
      "[[2492848      11]\n",
      " [    795 2006346]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9996\n",
      "F1-Score: 0.9998\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.16733336448669434 seconds\n",
      "Confusion Matrix:\n",
      "[[2494074      23]\n",
      " [    992 2004911]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09148240089416504 seconds\n",
      "Confusion Matrix:\n",
      "[[2492361      23]\n",
      " [    985 2006631]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09559965133666992 seconds\n",
      "Confusion Matrix:\n",
      "[[2491958      22]\n",
      " [   1040 2006980]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.1794447898864746 seconds\n",
      "Confusion Matrix:\n",
      "[[2493395      24]\n",
      " [   1032 2005549]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.15926456451416016 seconds\n",
      "Confusion Matrix:\n",
      "[[2492136      17]\n",
      " [    973 2006874]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.13457179069519043 seconds\n",
      "Confusion Matrix:\n",
      "[[2493544      13]\n",
      " [   1010 2005433]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.12105226516723633 seconds\n",
      "Confusion Matrix:\n",
      "[[2492682      21]\n",
      " [   1035 2006262]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.14455556869506836 seconds\n",
      "Confusion Matrix:\n",
      "[[2494599      17]\n",
      " [   1014 2004370]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.14102435111999512 seconds\n",
      "Confusion Matrix:\n",
      "[[2493012      21]\n",
      " [   1006 2005961]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.14291620254516602 seconds\n",
      "Confusion Matrix:\n",
      "[[2495413      19]\n",
      " [   1021 2003547]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.14476394653320312 seconds\n",
      "Confusion Matrix:\n",
      "[[2493660      20]\n",
      " [    979 2005341]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9998\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09061527252197266 seconds\n",
      "Confusion Matrix:\n",
      "[[2493789      15]\n",
      " [   1046 2005150]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.12486481666564941 seconds\n",
      "Confusion Matrix:\n",
      "[[2493885      17]\n",
      " [    976 2005122]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9998\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.09392094612121582 seconds\n",
      "Confusion Matrix:\n",
      "[[2493185      24]\n",
      " [   1029 2005762]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.15212345123291016 seconds\n",
      "Confusion Matrix:\n",
      "[[2493436      22]\n",
      " [   1059 2005483]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9997\n",
      "AUC Score: 1.0000\n",
      "test read\n",
      "Prediction time: 0.15258073806762695 seconds\n",
      "Confusion Matrix:\n",
      "[[2250172      16]\n",
      " [    881 1809609]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.9995\n",
      "F1-Score: 0.9998\n",
      "AUC Score: 1.0000\n",
      "data read\n"
     ]
    }
   ],
   "source": [
    "with open(\"training_record.txt\", mode='a') as file:\n",
    "\n",
    "    for i in range(20):\n",
    "\n",
    "        # Read the data back from the binary file.\n",
    "        with open(f'/data2/xpgeng/iPC815/X_{i}.pickle', 'rb') as f:\n",
    "            X_train = pickle.load(f)\n",
    "\n",
    "        with open(f'/data2/xpgeng/iPC815/y_{i}.pickle', 'rb') as f:\n",
    "            y_train = pickle.load(f)\n",
    "            \n",
    "        print('data read')\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        # 记录训练开始时间\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 运行模型\n",
    "        num_train_epochs = 20\n",
    "        model, train_losses, validation_losses = run_pytorch_MLP(\n",
    "            X_train, X_val, y_train, y_val, batch_size=500, \n",
    "            learning_rate=1e-4, weight_decay=1e-3, num_train_epochs=num_train_epochs)\n",
    "\n",
    "        # 记录训练结束时间\n",
    "        end_time = time.time()\n",
    "\n",
    "        # 计算训练时间\n",
    "        training_time = end_time - start_time\n",
    "        #print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        for j in range(20):\n",
    "            # Read the data back from the binary file.\n",
    "            with open(f'/data2/xpgeng/iPC815/X_{j}.pickle', 'rb') as f:\n",
    "                X_test = pickle.load(f)\n",
    "\n",
    "            with open(f'/data2/xpgeng/iPC815/y_{j}.pickle', 'rb') as f:\n",
    "                y_test = pickle.load(f)\n",
    "\n",
    "            print('test read')\n",
    "            \n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # 将 numpy 数据转换回 torch tensor 并将其移至正确的设备\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "            model.eval()  # 设置模型为评估模式\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_test_tensor)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predicted = predicted.cpu().numpy()\n",
    "                y_test_np = y_test  # 直接使用 y_test，因为它已经是 numpy 数组\n",
    "            end_time = time.time()\n",
    "            print(f\"Prediction time: {end_time - start_time} seconds\")\n",
    "\n",
    "            # 计算混淆矩阵\n",
    "            conf_matrix = confusion_matrix(y_test_np, predicted)\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(conf_matrix)\n",
    "\n",
    "            # 计算 Precision, Recall 和 F1-Score\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_test_np, predicted, average='binary')\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "            # 计算 AUC\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            auc_score = roc_auc_score(y_test_np, probabilities)\n",
    "            print(f\"AUC Score: {auc_score:.4f}\")\n",
    "            \n",
    "            record = (\n",
    "                f\"{i}, \"\n",
    "                f\"{round(training_time, 3)}, \"\n",
    "                f\"{j}, \"\n",
    "                f\"{round(end_time - start_time, 3)}, \"\n",
    "                f\"{round(precision, 3)}, \"\n",
    "                f\"{round(recall, 3)}, \"\n",
    "                f\"{round(f1, 3)}, \"\n",
    "                f\"{round(auc_score, 3)}\\n\"\n",
    "            )\n",
    "\n",
    "            file.write(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d672d",
   "metadata": {},
   "source": [
    "Train all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becff69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def run_pytorch_MLP(model, X_train, X_test, y_train, y_test, \n",
    "                    batch_size, learning_rate, weight_decay, num_train_epochs, device):\n",
    "    # 使用 SMOTE\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 将 numpy 数据转换为 torch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 初始化模型\n",
    "    #model = MLP()\n",
    "    model.to(device)  # 移动模型到 GPU\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(num_train_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test.to(device))\n",
    "            validation_loss = criterion(outputs, y_test.to(device))\n",
    "        \n",
    "        print(f'Epoch {epoch+1} - Train Loss: {running_loss / len(train_loader):.3f}, Validation Loss: {validation_loss.item():.3f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75abfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数和设备\n",
    "batch_size = 500\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.001\n",
    "num_train_epochs = 20\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "a = time.time()\n",
    "# 加载测试数据集（假设测试集是固定的）\n",
    "X_test = load_data('/data2/xpgeng/iPC815/X_0.pickle')\n",
    "y_test = load_data('/data2/xpgeng/iPC815/y_0.pickle')\n",
    "\n",
    "# 循环读取每个数据分片\n",
    "for i in range(20):\n",
    "    X_train = load_data(f'/data2/xpgeng/iPC815/X_{i}.pickle')\n",
    "    y_train = load_data(f'/data2/xpgeng/iPC815/y_{i}.pickle')\n",
    "    \n",
    "    # 如果是第一次迭代，初始化模型\n",
    "    if i == 0:\n",
    "        model = MLP()\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        model = run_pytorch_MLP(model, X_train, X_test, y_train, y_test, batch_size, learning_rate, weight_decay, num_train_epochs, device)\n",
    "    else:\n",
    "        # 继续训练模型\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        model = run_pytorch_MLP(model, X_train, X_test, y_train, y_test, batch_size, learning_rate, weight_decay, num_train_epochs, device)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'mlp_model.pth')\n",
    "\n",
    "#print(\"Model saved successfully.\")\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "with open(\"all_time.txt\", \"w\") as file:\n",
    "    file.write(f\"all time: {b-a:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a704e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bdc8314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bff646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorchh]",
   "language": "python",
   "name": "conda-env-.conda-pytorchh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
